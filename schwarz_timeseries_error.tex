%% Copernicus Publications Manuscript Preparation Template for LaTeX Submissions
%% ---------------------------------
%% This template should be used for copernicus.cls
%% The class file and some style files are bundled in the Copernicus Latex Package, which can be downloaded from the different journal webpages.
%% For further assistance please contact Copernicus Publications at: production@copernicus.org
%% https://publications.copernicus.org/for_authors/manuscript_preparation.html


%% Please use the following documentclass and journal abbreviations for preprints and final revised papers.

%% 2-column papers and preprints
\documentclass[journal abbreviation, manuscript]{copernicus}



%% Journal abbreviations (please use the same for preprints and final revised papers)


% Advances in Geosciences (adgeo)
% Advances in Radio Science (ars)
% Advances in Science and Research (asr)
% Advances in Statistical Climatology, Meteorology and Oceanography (ascmo)
% Aerosol Research (ar)
% Annales Geophysicae (angeo)
% Archives Animal Breeding (aab)
% Atmospheric Chemistry and Physics (acp)
% Atmospheric Measurement Techniques (amt)
% Biogeosciences (bg)
% Climate of the Past (cp)
% DEUQUA Special Publications (deuquasp)
% Earth Surface Dynamics (esurf)
% Earth System Dynamics (esd)
% Earth System Science Data (essd)
% E&G Quaternary Science Journal (egqsj)
% EGUsphere (egusphere) | This is only for EGUsphere preprints submitted without relation to an EGU journal.
% European Journal of Mineralogy (ejm)
% Geochronology (gchron)
% Geographica Helvetica (gh)
% Geoscience Communication (gc)
% Geoscientific Instrumentation, Methods and Data Systems (gi)
% Geoscientific Model Development (gmd)
% History of Geo- and Space Sciences (hgss)
% Hydrology and Earth System Sciences (hess)
% Journal of Bone and Joint Infection (jbji)
% Journal of Environmentally Compatible Air Transport System (jecats)
% Journal of Micropalaeontology (jm)
% Journal of Sensors and Sensor Systems (jsss)
% Magnetic Resonance (mr)
% Mechanical Sciences (ms)
% Natural Hazards and Earth System Sciences (nhess)
% Nonlinear Processes in Geophysics (npg)
% Ocean Science (os)
% Polarforschung - Journal of the German Society for Polar Research (polf)
% Proceedings of the International Association of Hydrological Sciences (piahs)
% Proceedings of the International Ocean Drilling Programme (piodp)
% Safety of Nuclear Waste Disposal (sand)
% Scientific Drilling (sd)
% SOIL (soil)
% Solid Earth (se)
% State of the Planet (sp)
% The Cryosphere (tc)
% Weather and Climate Dynamics (wcd)
% Web Ecology (we)
% Wind Energy Science (wes)


%% \usepackage commands included in the copernicus.cls:
%\usepackage[german, english]{babel}
%\usepackage{tabularx}
%\usepackage{cancel}
%\usepackage{multirow}
%\usepackage{supertabular}
%\usepackage{algorithmic}
%\usepackage{algorithm}
%\usepackage{amsthm}
%\usepackage{float}
%\usepackage{subfig}
%\usepackage{rotating}


\begin{document}

%\title{Time-series uncertainty with Wiener fouling and drift}
\title{Uncertainty of time-series measurements subject to Wiener fouling and calibration-drift}



% \Author[affil]{given_name}{surname}

\Author[1]{Gregory}{Schwarz}
\Author[1][thodson@usgs.gov]{Timothy O.}{Hodson} %% correspondence author

\affil[1]{U.S. Geological Survey Water Resources Mission Area}

%% The [] brackets identify the author with the corresponding affiliation. 1, 2, 3, etc. should be inserted.

%% If an author is deceased, please add \deceased[$Deceased date if applicable$]{$Author number$} (e.g. \deceased[13 November 2015]{2}) at the end of the affiliations. The author number depends on the placement of the author in the author list, e.g. the third author has number 3.


%% If authors contributed equally, please add \equalcontrib{$Author numbers$} (e.g. \equalcontrib{1,3}) at the end of the affiliations. The author number depends on the placement of the author in the author list, e.g. the third author has number 3.




\runningtitle{Wiener Error}

\runningauthor{Schwarz and Hodson}





\received{}
\pubdiscuss{} %% only important for two-stage journals
\revised{}
\accepted{}
\published{}

%% These dates will be inserted by Copernicus Publications during the typesetting process.


\firstpage{1}

\maketitle



\begin{abstract}
Test
\end{abstract}


\copyrightstatement{TEXT} %% This section is optional and can be used for copyright transfers.


\introduction  %% \introduction[modified heading if necessary]
%
TEXT

%TODO transition here
In a measuring device 
In practice, determination of these errors is used to correct the raw measurements
Later on, these 

% USGS operates a network of several thousands of such devices
% so a flexible approach
% Introduce Wagner here as the standard USGS methodology for correcting
% time-series measurements for drift and fouling,
% which is why we reference instead of more standard texts on measurement error.

\subsection{Preliminaries}
%
Let $X$ denote the true value of some variable
and let $Y$ denote its measured value.
The absolute error $E$ and percent error $\%E$ are given by
%
\begin{equation}
    E = Y - X
    \label{eq:absolute_error}
    \text{,}
\end{equation}
%
and
%
\begin{equation}
    \%E = 100 \times \frac{Y - X}{Y}
    \label{eq:percent_error}
    \text{,}
\end{equation}
%
so that $\%E$ is expressed as a percentage of the measured value.
For simplicity, we will instead work in terms of the fractional error
%
\begin{equation}
    \mathcal{E} = \frac{Y - X}{Y} = \frac{\%E}{100}
    \label{eq:fractional_error}
    \text{,}
\end{equation}
%
and only convert back to a percentage when needed.
Either scale (absolute or relative) may be used for uncertainty quantification,
depending on the characteristics of the measurement device.

We assume that the measurement error has three components---
fouling $E_f$, calibration-drift $E_d$,
and instrument precision $E_p$---
that add on the absolute scale,
%
\begin{equation}
    E = E_f + E_d + E_p
    \text{.}
\end{equation}
%
On the relative scale, these components combine multiplicatively,
%
\begin{equation}
    1 + \mathcal{E} = (1 + \mathcal{E}_f)(1 + \mathcal{E}_d)(1 + \mathcal{E}_p)
    \text{,}
\end{equation}
%
but for small errors (less than a few percent),
the relation is approximately additive,
%
\begin{equation}
    \mathcal{E} \approx \mathcal{E}_f + \mathcal{E}_d + \mathcal{E}_p
    \text{.}
\end{equation}
%

Fouling arises from physical, chemical, or biological buildup that biases the measurement.
It is assessed by taking check measurements immediately
before (subscript $b$) and after (subscript $a$) cleaning the device.
Under steady conditions,
the fouling error is given by
%
\begin{equation}
    E_f = Y_b - Y_a
    \text{,}
\end{equation}
%
where $Y_b$ and $Y_a$ are the measurements before and after cleaning, respectively.
If the environment changes during the cleaning,
then the fouling check must account for that change by using a reference device,
which measures the same environment during the cleaning period,
%
\begin{equation}
    E_f = (Y_b - Y_a) - (Z_b - Z_a)
    \qquad \text{or} \qquad
    \mathcal{E}_f = \frac{(Y_b - Y_a) - (Z_b - Z_a)}{Y_b}
    \label{eq:fouling_error}
    \text{,}
\end{equation}
%
where $Z_b$ and $Z_a$ are the before-and-after reference measurements
\citep[][noting they flip the sign of the error]{Wagner_2006}.

The calibration-drift represents any residual bias after cleaning the device,
which is measured by comparing a clean measurement against a known standard.
Let $Z_s$ be the standard value and let $Y_s$ be the clean measurement of $Z_s$.
Then the calibration-drift error is given by
%
\begin{equation}
    E_d = Y_s - Z_s
    \qquad \text{or} \qquad
    \mathcal{E}_{d} = \frac{Y_s - Z_s}{Y_s}
    \label{eq:drift_error}
    \qquad \text{\citep{Wagner_2006}.}
\end{equation}
%

Lastly, precision error $E_p$ represents irreducible measurement noise,
which is modeled using a Gaussian distribution,
%
\begin{equation}
    E_p \sim \mathcal{N}(0 ,\, \sigma_p^2)
    \qquad \text{or} \qquad
    \mathcal{E}_p \sim \mathcal{N}(0 ,\, \sigma_p^2)
    \text{,} \quad \text{where} \quad
    \sigma_p := \frac{\sigma_{\%p}}{100}
    \quad \text{for} \quad \mathcal{E}_p
    \label{eq:precision_error}
    \text{,}
\end{equation}
%
with variance given by
%
\begin{equation}
    v_p :=
    \operatorname{Var}[E_p] = \sigma_p^2
    \label{eq:precision_variance}
    \text{.}
\end{equation}
%
In practice, the precision is determined under controlled conditions
and reported in the device specifications
(sometimes called the "accuracy")
as the $2\sigma_p$ or 95\% confidence interval.
We typically assume fouling and drift errors have the same scale (absolute or relative)
as the precision, but this is not a requirement.

\subsection{The Measurement Procedure}

A clean, calibrated device is deployed into the environment
to measure a variable of interest.
Over time, fouling and calibration-drift errors accumulate
and bias the raw measurements.
To correct this bias, fouling and calibration are checked periodically.
Each check may quantify one or both components
and may involve cleaning or recalibration,
which resets the corresponding error to zero.
After each check, the raw time-series measurements are corrected
for any observed fouling and calibration-drift,
and these corrections are propagated between check points.
The uncertainty of the corrected measurements therefore includes uncertainty
from the check measurements as well as uncertainty about the accumulation of
error through time.

\subsection{Wiener-Process Error Model}

We model drift and fouling errors as a Wiener process
with an optional drift term $\mu$.
A Wiener process is a continuous-time stochastic process
with independent, normally distributed increments
whose variance grows linearly with elapsed time.
In particular, for a process $\{X_t\}_{t \ge 0}$
with drift $\mu$ and diffusion rate $\sigma^2$,
the increment over time $t$ satisfies
%
\begin{equation}
    X_t - X_0 \sim
    \mathcal{N}\!\left(\mu t,\; \sigma^2 t\right)
    \qquad \text{for } t \ge 0
    \qquad
    \text{\citep{Taylor_1998}.}
\end{equation}
%
The drift term $\mu$ represents the mean rate of change
(with $\mu=0$ for a classical Wiener process)
and is important for devices that exhibit systematic bias,
such as a device that gradually loses responsiveness
due to the degradation of a consumable component,
like a reagent in a colorimetric analyzer.

Let $E_t$ be a random variable representing the error at time $t$,
and $e_t$ be its realization (observed value).
Suppose we observe the error at times $0 = t_0 < t_1 < t_2 < \cdots < t_K = T$.
To simplify notation, we write $e_k := e_{t_k}$,
such that $E_{t_k} = e_k$ for $k = 0, 1, \ldots, K$.
Thus, $t_k - t_{k-1}$ represents the time elapsed between subsequent observations
$e_{k-1}$ and $e_k$,
and the subscript $k$ serves as a placeholder for either fouling $f$ or drift $d$ terms,
$k \in \{f, d\}$.

First, consider the case after observing the error at time $t_{k-1}$,
but before observing the error at time $t_k$.
We refer to this as an open interval,
which occurs during real-time uncertainty estimation.
In contrast, a closed interval is bracketed by
observations at both $t_{k-1}$ and $t_k$,
and the conditional mean and variance are revised after
accounting for the observation at $t_k$.

For an open interval,
the conditional distribution of the Wiener-process error is
%
\begin{equation}
    p(e_t \mid E_{k-1} = e_{k-1})
    =
    \mathcal{N}(m^o(t),\, v^o(t))
    \text{,} \qquad
    t > t_{k-1}
    %\mathcal{N}(\delta_{k-1}  e_{k-1} + \mu t ,\, \sigma^2 t)
\end{equation}
%
%\begin{equation}
%    E_{t} \mid E_0 = e_0 \sim \mathcal{N}(e_0 + \mu t ,\; \sigma^2 t) \text{,}
%    \label{eq:wiener_process}
%\end{equation}
%
with conditional mean and variance given by
\begin{align}
    m^o(t) &:=
        \mathbb{E}\left[E_t \mid E_{k-1} = e_{k-1} \right]
        = \delta_{k-1} e_{k-1} + \mu (t - t_{k-1})
        \qquad \text{and}
        \label{eq:wiener_mean}\\
    v^o(t) &:=
        \operatorname{Var}\left[E_t \mid E_{k-1} = e_{k-1} \right]
        = \sigma^2 (t - t_{k-1})
        \label{eq:wiener_variance}
    \text{.}
\end{align}
%
where $\delta_{k-1}$ indicates whether the error process has been reset
due to cleaning or recalibration,
\begin{equation}
    \delta_{k-1} =
    \begin{cases}
        0, & \text{reset at } t_{k-1} \\
        1, & \text{otherwise}
    \end{cases}
    \text{,}
\end{equation}
$e_{k-1}$ is the error at time $t_{k-1}$,
%$\mathcal{N}$ is the normal distribution
%specified by its mean and variance,
$\mu$ is the drift rate (mean change per unit time),
$\sigma^2$ is the instantaneous variance rate (variance per unit time).
Thus for any $t \ge 0$,
it follows that the conditional mean and variance are
%
%
%
Later on, upon observing the error at time $t_k$,
the conditional distribution of $E_t$ is updated.
A Wiener process conditioned to start and end at specified values
is known as a Brownian bridge \citep{Taylor_1998}.
To simplify notation, 
let $\lambda(t)$ be the linear interpolation weight,
%
\begin{equation}
    \lambda_k(t) = \frac{t - t_{k-1}}{t_k - t_{k-1}}
    \text{,} \qquad
    k \in \{f, d\}
\end{equation}
%
such that $\lambda_f(t)$ denotes the fouling weight
for the interval $t \in \left[t_{f-1}, t_f \right]$.
The conditional distribution of the bridge at time
$t$ is
%
\begin{equation}
    p(e_t \mid E_{t_{k-1}} = e_{k-1},\, E_{t_k} = e_k)
    =
    \mathcal{N} \left(
        m^c(t), v^c(t)
        %\delta_{k-1} \left( 1 - \lambda(t) \right)e_{k-1}
        %+ 
        %\lambda(t) e_k,\;
        %\sigma^2 (1 - \lambda(t)) \lambda(t) (t_k - t_{k-1})
    \right)
    \text{,} \qquad
    t \in \left[t_{k-1},\, t_k \right]
\end{equation}
%
with conditional mean and variance given by
%
\begin{align}
    m^c(t) &:=
        \mathbb{E}\left[ E_t \mid E_{t_{k-1}} = e_{k-1} ,\, E_{t_k} = e_k \right]
        =
        \delta_{k-1} \left( 1 - \lambda(t) \right) e_{k-1} + \lambda(t) e_k
        \qquad \text{and}
        \label{eq:bridge_mean} \\
    v^c(t) &:=
    \operatorname{Var} \left[ E_t \mid E_{t_{k-1}} = e_{k-1} ,\, E_{t_k} = e_k \right]
        = \sigma^2 \frac{(t - t_{k-1})(t_{k} - t)}{t_{k} - t_{k-1}} 
        % = \sigma^2 (1 - \lambda_k(t)) (t - t_{k-1})
        \label{eq:bridge_variance}
    \text{.}
\end{align}
%
Let $\lambda^+_k(t)$ be the linear interpolation weight,
extended by
%
\begin{equation}
    \lambda^+_k(y) :=
    \begin{cases}
        1, & t < t_{1} \\
        \frac{t - t_{k-1}}{t_k - t_{k-1}}, & t \in [t_{k-1}, t_k] \\
        0, & t > t_{K}
    \end{cases}
    \text{,}
\end{equation}
%
such that $\lambda^+_k(t) = 1$ or $0$ when extrapolating
below or above the standard range, respectively.
Also let $\phi^+_k(t)$ define the bridge factor, extended by
%
\begin{equation}
    \phi^+_k(t) :=
    \begin{cases}
        (t_{1} - t), & t < t_{1} \\
        \frac{(t - t_{k-1})(t_{k} - t)}{(t_{k} - t_{k-1})},
        & t \in [t_{k-1}, t_{k}] \\
        (t - t_{K}), & t > t_{K} 
    \end{cases}
    \text{.}
\end{equation}
%
By substituting these definitions into the equations for the mean and covariance,
the open and closed forms become equivalent,
%
\begin{align}
    m_k(t) &= \delta_{k-1} \left( 1 - \lambda^+_k(t) \right)e_{k-1} + \lambda^+_k(t) e_k
    \label{eq:unified_wiener_mean}
    \qquad \text{and} \qquad \\
    v_k(t) &= \sigma^2 \phi^+_k(t)
    \label{eq:unified_wiener_variance}
    \text{,}
\end{align}
%
thereby eliminating the need for superscripts ($m^o$, $m^c$, etc.).

\subsection{Check-Measurement Uncertainty}

Recall that the checks measurements have their own uncertainty, which must be propagated through the error model.
We will explain the general statistical procedure, then apply it to fouling and calibration-drift.

Formally, we define a Gaussian bridge with uncertain endpoints,
where the expectation and variance of the endpoints is given by
%
\begin{equation}
    \mathbb{E}\left[ E_{k-1}\right] = m_{k-1}
    \text{,} \qquad
    \mathbb{E}\left[ E_{k}\right] = m_{k}
    \text{,} \qquad
    \operatorname{Var}\left[ E_{k-1}\right] = v_{k-1}
    \text{,} \qquad
    \operatorname{Var}\left[ E_{k}\right] = v_{k}
    \text{,} \qquad
    \operatorname{Cov}\left[ E_{k-1}, E_{k}\right] = 0
\end{equation}
%
The Gaussian bridge is given by 
%
\begin{equation}
    E_t = (1 - \lambda^+_k(t)) E_{k-1} + \lambda^+_k(t) E_k + W_t
    \text{,} \qquad
    W_t \sim \mathcal{N}\left(0, \sigma^2 \phi^+_k(t)\right)
    \text{.}
\end{equation}
%
By linearity of expectation,
%
\begin{align}
    \mathbb{E}[E_t] &= (1 - \lambda^+_k(t)) \mathbb{E}[E_{k-1}]
                        + \lambda^+_k(t) \mathbb{E}[E_k] + \mathbb{E}[W_t]
                        \notag \\
                    &= (1 - \lambda^+_k(t)) m_{k-1} + \lambda^+_k(t) m_{k}
\end{align}
%
Because $W_t$ is independent of the endpoint errors $E_{k-1}$ and $E_k$,
the variance decomposes into separate terms.
Applying the variance formula for a linear combination yields
%
\begin{align}
    \operatorname{Var}[E_t]
        &= \operatorname{Var}[
            (1 - \lambda^+_k(t)) E_{k-1}
            +
            \lambda^+_k(t) E_{k}
            ]
            + \operatorname{Var}[W_t]
            \notag \\
        &=  \underbrace{
            (1 - \lambda^+_k(t))^2 \operatorname{Var}[E_{k-1}]
            + \lambda^+_k(t)^2 \operatorname{Var}[E_{k}]
            }_{\tilde{v}_k(t)}
            + 
            \underbrace{\sigma^2 \phi^+_k(t)}_{v_k(t)}
    \text{,}
\end{align}
%
where $\tilde{v}_k(t)$ represents the contribution from check-measurement uncertainty,
\begin{equation}
    \tilde{v}_k(t) := 
        (1 - \lambda^+_k(t))^2 \operatorname{Var}[E_{k-1}]
        + \lambda^+_k(t)^2 \operatorname{Var}[E_{k}]
    \label{eq:check_variance}
    \text{.}
\end{equation}
%
Assuming the check-measurements have constant variance
$\operatorname{Var}[E_k]$,
the conditional variance at time $t$ is
%
\begin{equation}
    \tilde{v}_k(t) = \left(
                        (1 - \lambda^+_k(t))^2 + \lambda^+_k(t)^2
                      \right) \operatorname{Var}[E_k]
    \label{eq:check_constant_variance}
    \text{,}
\end{equation}
%
which simplifies to $ \tilde{v}^o_k(t) = \operatorname{Var}[E_k]$
during open intervals.
The following sections derive expressions for
$\operatorname{Var}[E_f]$ and $\operatorname{Var}[E_d]$,
which substite in the $\operatorname{Var}[E_k]$ term
of Equation~\ref{eq:check_constant_variance}.
Later, we will relax the constant-variance assumption,
and refer back to the full expression for the check variance
(Equation~\ref{eq:check_variance}).

\subsubsection{Fouling-Check Uncertainty}

For a fouling check, we assume the measuring $m$ and reference $r$
devices have known precisions $\sigma_p$ and $\sigma_r$, respectively,
and their errors are normally distributed and independent,
\begin{equation}
    E^{m} \sim \mathcal{N}\left(0, \sigma^2_p \right)
    \text{,} \qquad
    E^{r} \sim \mathcal{N}\left(0, \sigma^2_r \right)
    \text{,} \qquad
    E^{m} \perp E^{r}
    \text{.}
\end{equation}
%
Let $Y$ and $Z$ denote the primary and reference measurements,
and $Z$ their true values,
%
\begin{equation}
    Y = X^m + E^{m}
    \text{,} \qquad
    Z = X^r + E^{r}
\end{equation}
%
Substituting these back into the fouling error (Equation~\ref{eq:fouling_error})
gives
%
\begin{align}
    E_f &= (Y_b - Y_a) - (Z_b - Z_a) \notag \\
        &= \left((X^m_b + E^m_{b}) - (X^m_a + E^m_{a})\right)
           - \left((X^r_b + E^r_{b}) - (X^r_a + E^r_{a})\right) \notag \\
        &= (E^m_{b} - E^m_{a}) - (E^r_{b} - E^r_{a})
    \text{.}
\end{align}
%
By independence ($E^{m} \perp E^{r}$), the variance is
\begin{align}
    \operatorname{Var}[E_f]
        &= \operatorname{Var}[E^m_b - E^m_a]
          + \operatorname{Var}[E^r_b - E^r_a]
\end{align}
%
Furthermore, we assume the measuring device uses internal filtering
(e.g., time averaging),
so its error is perfectly correlated during the check,
%
\begin{equation}
    \operatorname{Corr} \left( E^{m}_{a},\, E^{m}_{b} \right) = 1
    \quad \Rightarrow \quad
    \operatorname{Var}[E^m_b - E^m_a] = 0
    \text{,}
\end{equation}
%
If the reference device also uses filtering,
then
\begin{equation}
    \operatorname{Corr}(E_{z_a},\, E_{z_b}) = 1 
    \quad \Rightarrow \quad
    \operatorname{Var}[E_f] = 0
    \text{;}
\end{equation}
otherwise, if its errors are independent,
then
\begin{equation}
    \operatorname{Corr}(E_{z_a}, E_{z_b}) = 0
    \quad \Rightarrow \quad
    \operatorname{Var}[E_f]
    = \operatorname{Var}[E^r_b] + \operatorname{Var}[E^r_a]
    = 2 \sigma^2_r
    \text{.}
\end{equation}

\subsubsection{Calibration-Check Uncertainty}

For a calibration check, we assume the standard and measurement device have known precisions
$\sigma_s$ and $\sigma_p$, respectively,
and their errors are normally distributed and independent,
%
\begin{equation}
    E^{s} \sim \mathcal{N}\left(0, \sigma^2_s \right)
    \text{,} \qquad
    E^{m} \sim \mathcal{N}\left(0, \sigma^2_p \right)
    \text{,} \qquad
    E^{s} \perp E^{m}
    \text{.}
\end{equation}
%
Let $Y_s$ and $Z_s$ denote the measurement and standard values,
\begin{equation}
    Y_s = X_s + E^{m}
    \text{,} \qquad
    Z_s = X_s + E^{s}
    \text{.}
\end{equation}
%
Substituting these variables into the drift error
(Equation~\ref{eq:drift_error}) yields
%
\begin{equation}
    E_d = (X_s + E^m) - (Z_s + E^s)
    \text{.}
\end{equation}
%
By independence ($E^{m} \perp E^{s}$), the variance is
%
\begin{equation}
    \operatorname{Var}[E_d]
        = \operatorname{Var}[E^m] + \operatorname{Var}[E^s]
        = \sigma^2_p + \sigma^2_s
    \text{.}
\end{equation}
%

\subsection{Multi-point Correction}

Sometimes multiple standards are used to calibrate the device.
For example, a pH meter might be calibrated against standards at pH 4, 7, and 10.
In that case, the expected drift-correction for a measurement is 
a linear interpolation between
the corrections for the two nearest standards \citep{Wagner_2006}.

Given standard values $z_s$ for $s = 1, 2, \ldots, S$,
the conditional mean is a bilinear interpolation between four points,
$e_{k-1,s-1}$, $e_{k-1,s}$, $e_{k,s-1}$, and $e_{k,s}$,
denote as the set
$\{e_{i,j}\}$ where $i\in\{k-1,k\}$ and $j\in\{s-1,s\}$.
%
% bilinear interpolation between four points
% e{k,s} and so on
% in terms of \lambda_k(t) \lambda_s(x)
\begin{align}
    m(t, y)
    &:=
    \mathbb{E}\left[
        E_{t,y}\,\mid\,
        \{\,E_{t_i,y_j}=e_{i,j}\,\}_{\,i\in\{k-1,k\},\, j\in\{s-1,s\}}
        \right] \notag \\
    &=
    (1-\lambda^+_k(t),\;\lambda^+_k(t))
    \begin{bmatrix}
        \delta_{k-1} e_{k-1,s-1} & \delta_{k-1} e_{k-1,s} \\
        e_{k,s-1}   & e_{k,s}
    \end{bmatrix}
    \begin{bmatrix}
        1-\lambda^+_s(y) \\
        \lambda^+_s(y)
    \end{bmatrix}.
\end{align}
Expanding the right-hand side yields
\begin{align}
    m(t,y)
    &=
    (1 - \lambda_k(t))(1 - \lambda_s(y)) \delta_{k-1} e_{k-1,s-1} \notag \\
    &\quad
    + (1 - \lambda_k(t)) \lambda_s(y) \delta_{k-1} e_{k-1,s} \notag \\
    &\quad
    + \lambda_k(t)(1 - \lambda_s(y)) e_{k,s-1} \notag \\
    &\quad
    + \lambda_k(t) \lambda_s(y) e_{k,s}
    \text{,}
\end{align}
which satisfies the conditions for the four corner points,
\begin{align}
    m(t_{k-1}, y_{s-1}) &=  \delta_{k-1}e_{k-1,s-1} \text{,} \notag \\
    m(t_{k-1}, y_{s})   &=  \delta_{k-1}e_{k-1,s} \text{,} \notag \\
    m(t_{k}, y_{s-1})   &=  e_{k,s-1} \text{,} \notag \\
    m(t_{k}, y_{s})     &=  e_{k,s} \text{.}
\end{align}
%
The conditional variance is given by
%
\begin{align}
    v(t, y)
    &:=
    \operatorname{Var}\left[
        E_{t,y}\,\mid\,
        \{\,E_{t_i,y_j}=e_{i,j}\,\}_{\,i\in\{k-1,k\},\, j\in\{s-1,s\}}
        \right] \notag \\
    &=
    \left[
        \left(1 - \lambda^+_s(y)\right)^2 \sigma^2_{s-1}
        +
        \lambda^+_s(y)^2 \sigma^2_{s}
    \right]
    \underbrace{
        \frac{\left(t - t_{k-1}\right) \left(t_{k} - t\right)}
        {\left(t_{k} - t_{k-1}\right)}
    }_{\text{time-variance factor}} \notag \\
    &=
    \left[
    \left(1 - \lambda^+_s(y)\right)^2 \sigma^2_{s-1}
    +
    \lambda^+_s(y)^2 \sigma^2_{s}
    \right]
    \phi^+_k(t)
    \label{eq:multi_point_variance}
\end{align}
% TODO need to verify closed-interval variance
Here, we might reasonably assume
\begin{equation}
    v(t, y) = \sigma^2 \phi^+_k(t)
\end{equation}

% discuss imputation of missing standards here
% specifically, by using the v_c term

\subsection{Combined Error}
% TODO change superscript notations to $o$ and $b$ for bridge
The conditional mean and variance given by the sum of the individual components,
%
\begin{align}
m(t) &=
    m_{f}(t)
    +
    m_{d}(t, y)
    +
    m_{c}(t, y)
    \qquad \text{and}
    \label{eq:total_mean_open} \\
v(t) &=
    v_{f}(t)
    +
    \tilde{v}_{f}(t)
    +
    v_{d}(t, y)
    +
    \tilde{v}_{d}(t, y)
    +
    v_{p}(t)
    \text{,}
\end{align}
%
where $f$, $d$, and $p$ denote the fouling, drift, and precision, respectively
(Equations~\ref{eq:unified_wiener_variance},
           \ref{eq:check_variance},
           \ref{eq:multi_point_variance},
           \ref{eq:precision_variance},
TODOXXX (There will be 5)).

FIGURE HERE

\begin{figure*}[t]
%\includegraphics[width=12cm]{FILE NAME}
\caption{TEXT}
\label{fig:}
\end{figure*}
%



\subsection{Corrected Measurement and Confidence Interval}

Let $X_t$ denote the true value at time $t$,
and let $E_t$ denote the measurement error so that $Y_t = X_t + E_t$.
%Define $m(t) := \mathbb{E}[E_t]$ and $v(t) := \operatorname{Var}(E_t)$.
Then the bias-corrected estimate of $X_t$ is
%
\begin{equation}
    x(t) := \mathbb{E}\!\left[X_t \mid Y_t = y_t\right]
        = y_t - m(t)
        \text{,}
\end{equation}
%
with approximate confidence interval
%
\begin{equation}
    \text{CI} = x(t) \pm q_{1-\alpha/2} \sqrt{v(t)}
    \text{, }
\end{equation}
%
where $q_{1-\alpha/2}$ is the $(1-\alpha/2)$ quantile of the standard normal distribution
(e.g., $q_{0.975} = 1.96$ for a 95\% confidence interval).
Alternatively, for percent error $\%E_{t}$, the measured value is
%
\begin{equation}
    Y_t = \frac{X_t}{1 - \%E_{t}/100}
    % removing the 100x from the error simplifies here
\end{equation}
%
Then, on the original scale, the bias-corrected estimate of $X_t$ is
%
\begin{equation}
    x(t) := \mathbb{E}[X_t \mid Y_t = y_t]
        = y_t \left( 1 - \frac{\%m(t)}{100} \right)
        \text{.}
\end{equation}
%
and the confidence interval is
%
\begin{equation}
    \text{CI} = x(t) \pm q_{1-\alpha/2} \, \frac{y_t}{100} \sqrt{\%v(t)}
\text{.}
\end{equation}

\section{Parameter Estimation}

Letting
%
\begin{align}
    r(\mu_k) &:= e_k - \delta_{k-1} e_{k-1} - \mu_k (t - t_{k-1}) \\
    u(\sigma^2_k) &:= \sigma^2_k (t - t_{k-1}) + \sigma^2_p
\end{align}
%
and assuming the residuals are independent and identically distributed (i.i.d),
%
\begin{equation}
    e_k \mid \mu, \sigma^2
    \sim \mathcal{N}(
        \delta_{k-1} e_{k-1} + \mu_k (t - t_{k-1}),\;
        \sigma^2_k (t - t_{k-1}) + \sigma^2_p
    )
\end{equation}
%
then we can estimate $\mu$ and $\sigma^2_k$ by maximizing the log-likelihood function,
%
\begin{equation}
    \ell(\mu, \sigma^2)
    =
    %-\frac{K_i}{2} \ln(2 \pi)
    - \frac{1}{2} \sum_{k=1}^{K_i}
    \left[
        \log \left( u(\sigma^2_k) \right)
        +
        \frac{r(\mu_k)^2}{u(\sigma^2_k)}
    \right]
\end{equation}
%
\subsection{Multi-point in matrix form}
Let the calibration error be
%
\begin{equation}
    e_{t,y} = m(t,y) +
\end{equation}
%
%
Let
%
\begin{equation}
    \vec{e} :=
    \begin{bmatrix}
        e_{t_1,y_1} \\
        \vdots \\
        e_{t_N,y_N}
    \end{bmatrix}
    \text{,} \qquad
    \vec{m} :=
    \begin{bmatrix}
        m(t_1,y_1) \\
        \vdots \\
        m(t_N,y_N)
    \end{bmatrix}
    \text{,} \qquad
    \vec{F} :=
    \begin{bmatrix}
        \phi_k(t_1) & \phi_s(t_1) \\
        \vdots & \vdots \\
        \phi_k(t_N) & \phi_s(t_N)
    \end{bmatrix}
    \text{,} \qquad
    \vec{\Sigma}_k :=
    \begin{bmatrix}
        \sigma^2_{t} & \sigma_{tk} \\
        \sigma_{kt} & \sigma^2_{k}
    \end{bmatrix}
\end{equation}
%
\begin{equation}
    \vec{e} \sim \mathcal{N}(\vec{m}, \vec{\Sigma})
\end{equation}
%
with conditional variance given by
%
\begin{equation}
    \vec{\Sigma} =
    \vec{F} \vec{\Sigma}_v \vec{F}^T
    +
    \vec{\sigma}_{\varepsilon} \vec{I}_N
    +
    \vec{\sigma}_{p} \vec{I}_N
\end{equation}

The Gaussian log-likelihood function is
%
\begin{equation}
    \ell(\mu_k, \vec{\Sigma}^2_k, \sigma^2_{\varepsilon})
    =
    -\frac{1}{2}
    \left[
        N \log (2\pi) 
        +
        \log \det( \vec{\Sigma} )
        +
        (\vec{e} - \vec{m})^T \vec{\Sigma}^{-1} (\vec{e} - \vec{m})
    \right]
\end{equation}

Ignoring the covariance term, allows us to avoid the matrix inversion and determinant,
\begin{equation}
    \ell(\mu_k, \sigma^2_k, \sigma^2_{\varepsilon})
    =
    -\frac{N}{2} \log(2\pi)
    -\frac{1}{2} \sum_{i=1}^{N}
    \left[
        \log(u(\sigma^2_k)) + \frac{r(\mu_k)^2}{u(\sigma^2_k)}
    \right]
\end{equation}


\section{Hierarchical Modeling}
% \sigma_ij (site i and bin j )
The hierarchical estimate of the instantaneous variance rate $\sigma^2$ for site $i$ is given by
%
\begin{equation}
    \hat{\sigma}^2_i = X
\end{equation}
%
Inverse gamma distribution prior
%
\begin{equation}
    p(\sigma^2 \mid a ,\; b)
    =
    \frac{b^a}{\Gamma(a)} (\sigma^2)^{-(a+1)}
    \exp\left(-\frac{b}{\sigma^2}\right)
\end{equation}
%
\begin{equation}
    \bar{\sigma}
    \equiv
    \mathbb{E} \left[ \sigma^2 \mid a, b \right]
    = \frac{b}{a - 1}
\end{equation}
%
% TODO define residuals as r and sites as j
\begin{equation}
    \ln L(r \mid a ,\; b)
    =
    \sum_{j \in J}
    \left(
        - \frac{N_j}{2} \ln(2 \pi)
        + a \ln(b)
        + \ln \Gamma \left( \frac{N}{2} + a \right)
        - \left( \frac{N_j}{2} + a \right)
        \ln( \frac{N_j s^2_j}{2} + b)
        - \ln \Gamma(a)
    \right)
\label{eq:hierarchical_likelihood}
\end{equation}

The hierarchical estimate of the instantaneous variance rate $\sigma^2$ for site $j$ is given by
\begin{equation}
    \hat{\sigma}^2_j
    =
    \hat{w}_j s_j^2 + (1 - \hat{w}_j) \bar{\hat{\sigma}}^2
\end{equation}
where
\begin{equation}
    \hat{w}_j
    =
    \frac{N_j}{N_j + 2 (\hat{a} - 1)}
\end{equation}

\subsection{Simulation Experiments}
TEXT


\conclusions  %% \conclusions[modified heading if necessary]
TEXT

%% The following commands are for the statements about the availability of data sets and/or software code corresponding to the manuscript.
%% It is strongly recommended to make use of these sections in case data sets and/or software code have been part of your research the article is based on.

\codeavailability{TEXT} %% use this section when having only software code available

% \dataavailability{TEXT} %% use this section when having only data sets available
% \codedataavailability{TEXT} %% use this section when having data sets and software code available
% \sampleavailability{TEXT} %% use this section when having geoscientific samples available
% \videosupplement{TEXT} %% use this section when having video supplements available


\appendix
\section{Theorems}

\subsection{Variance of a Linear Combination}

For any random variables $X_1, X_2, \ldots, X_n$ with finite second moments, and any constants $a_1, a_2, \ldots, a_n$,
%
\begin{equation}
    Y = a_1 X_1 + a_2 X_2 + \ldots + a_n X_n
\end{equation}
%
the variance is given by
%
\begin{equation}
    \operatorname{Var}(Y)
    =
    \sum_{i=1}^{n} \sum_{j=1}^{n} a_i a_j \operatorname{Cov}(X_i, X_j)
\end{equation}
%
In the two-variable case,
\begin{equation}
    Y = a X + b Z
\end{equation}
then the variance is
\begin{equation}
    \operatorname{Var}(Y) = a^2 \operatorname{Var}(X) + b^2 \operatorname{Var}(Z) + 2ab \operatorname{Cov}(X, Z)
\end{equation}

\section{Proofs}    %% Appendix A

\section{SCRATCH}
\subsection{Precision model}
%\end{align}
% TODO revise to calibration error model
Recall that the precision of the measurement device $\sigma_{p}$ is assumed to be
constant over time (Equation~\ref{eq:precision_error}).
Thus, for normal errors, the conditional distribution is
%
\begin{equation}
    p(e_t \mid E_{t_{k-1}} = e_{k-1}) = \mathcal{N}
        \left(m^o(t),\,v^o(t)\right)
    \text{,}
\end{equation}
%
with conditional mean and variance given by
%
\begin{align}
    m^o(t)
        &:= \mathbb{E}\left[E_t \mid E_{t_{k-1}} = e_{k-1} \right]
        = 0
        \qquad \text{and} \\
    v^o(t)
        &:= \operatorname{Var}\left[E_t \mid E_{t_{k-1}} = e_{k-1} \right]
        = \sigma^2_{p}
        \text{.}
        \label{eq:precision_variance_open}
\end{align}
%
However, the conditional distribution for the closed interval is complicated
by the indirect effect of calibration.
In this case, the conditional variance is
%
% TODO XXX note the indirect effect of calibration
\begin{align}
    v^c(t)
        &:= \operatorname{Var}\left[E_t \mid E_{t_{k-1}} = e_{k-1} ,\, E_{t_k} = e_k \right]
        = \lambda_{d}(t) \chi_{d}(t) \sigma_p^2
        +
        \sigma_p^2
        \text{,}
        \label{eq:precision_variance_closed}
\end{align}
where $\chi_{d}$ is an indicator function
equal to 1 if $t \neq t_{d}$ and 0 otherwise,
\begin{equation}
\chi_{d}(t) =
\begin{cases}
    1, & t \neq t_{d} \\
    0, & t = t_{d}
\end{cases}
\label{eq:chi_function}
\text{,}
\end{equation}
which modulates the indirect effect of calibration-drift on the precision error.



\subsection{2D Interpolation}
the conditional mean of the Wiener-process error at time $t$ and reading $y$ is
%
\begin{align}
    m^o(t, y)
    &:=
    \mathbb{E}\left[
        E_{t,y}\,\mid\,
        E_{k-1,s-1} = e_{k-1,s-1}, \,
        E_{k-1,s} = e_{k-1,s}, \,
        \right] \notag \\
    &=
    (1-\lambda_s(y))
    \left[
        \delta_{k-1} e_{k-1,s-1} + \mu_{s-1}(t - t_{k-1})
    \right]
    +
    \lambda_s(y)
    \left[
         \delta_{k-1} e_{k-1,s} + \mu_{s} (t - t_{k-1})
    \right]
\end{align}
Note this is a linear interpolation between the two standards.
% and also applies to extraplolation
%


\noappendix       %% use this to mark the end of the appendix section. Otherwise the figures might be numbered incorrectly (e.g. 10 instead of 1).

%% Regarding figures and tables in appendices, the following two options are possible depending on your general handling of figures and tables in the manuscript environment:

%% Option 1: If you sorted all figures and tables into the sections of the text, please also sort the appendix figures and appendix tables into the respective appendix sections.
%% They will be correctly named automatically.

%% Option 2: If you put all figures after the reference list, please insert appendix tables and figures after the normal tables and figures.
%% To rename them correctly to A1, A2, etc., please add the following commands in front of them:

\appendixfigures  %% needs to be added in front of appendix figures

\appendixtables   %% needs to be added in front of appendix tables

%% Please add \clearpage between each table and/or figure. Further guidelines on figures and tables can be found below.



\authorcontribution{TEXT} %% this section is mandatory

\competinginterests{TEXT} %% this section is mandatory even if you declare that no competing interests are present

\disclaimer{TEXT} %% optional section

\begin{acknowledgements}
TEXT
\end{acknowledgements}




%% REFERENCES

%% The reference list is compiled as follows:

%% \begin{thebibliography}{}
%% 
%% \bibitem[AUTHOR(YEAR)]{LABEL1}
%% REFERENCE 1
%% 
%% \bibitem[AUTHOR(YEAR)]{LABEL2}
%% REFERENCE 2
%% 
%% \end{thebibliography}

%% Since the Copernicus LaTeX package includes the BibTeX style file copernicus.bst,
%% authors experienced with BibTeX only have to include the following two lines:
%%
\bibliographystyle{copernicus}
\bibliography{schwarz_timeseries.bib}
%%
%% URLs and DOIs can be entered in your BibTeX file as:
%%
%% URL = {http://www.xyz.org/~jones/idx_g.htm}
%% DOI = {10.5194/xyz}


%% LITERATURE CITATIONS
%%
%% command                        & example result
%% \citet{jones90}|               & Jones et al. (1990)
%% \citep{jones90}|               & (Jones et al., 1990)
%% \citep{jones90,jones93}|       & (Jones et al., 1990, 1993)
%% \citep[p.~32]{jones90}|        & (Jones et al., 1990, p.~32)
%% \citep[e.g.,][]{jones90}|      & (e.g., Jones et al., 1990)
%% \citep[e.g.,][p.~32]{jones90}| & (e.g., Jones et al., 1990, p.~32)
%% \citeauthor{jones90}|          & Jones et al.
%% \citeyear{jones90}|            & 1990



%% FIGURES

%% When figures and tables are placed at the end of the MS (article in one-column style), please add \clearpage
%% between bibliography and first table and/or figure as well as between each table and/or figure.

% The figure files should be labelled correctly with Arabic numerals (e.g. fig01.jpg, fig02.png).


%% ONE-COLUMN FIGURES

%%f
%\begin{figure}[t]
%\includegraphics[width=8.3cm]{FILE NAME}
%\caption{TEXT}
%\end{figure}
%
%%% TWO-COLUMN FIGURES
%
%%f
%\begin{figure*}[t]
%\includegraphics[width=12cm]{FILE NAME}
%\caption{TEXT}
%\end{figure*}
%
%
%%% TABLES
%%%
%%% The different columns must be seperated with a & command and should
%%% end with \\ to identify the column brake.
%
%%% ONE-COLUMN TABLE
%
%%t
%\begin{table}[t]
%\caption{TEXT}
%\begin{tabular}{column = lcr}
%\tophline
%
%\middlehline
%
%\bottomhline
%\end{tabular}
%\belowtable{} % Table Footnotes
%\end{table}
%
%%% TWO-COLUMN TABLE
%
%%t
%\begin{table*}[t]
%\caption{TEXT}
%\begin{tabular}{column = lcr}
%\tophline
%
%\middlehline
%
%\bottomhline
%\end{tabular}
%\belowtable{} % Table Footnotes
%\end{table*}
%
%%% LANDSCAPE TABLE
%
%%t
%\begin{sidewaystable*}[t]
%\caption{TEXT}
%\begin{tabular}{column = lcr}
%\tophline
%
%\middlehline
%
%\bottomhline
%\end{tabular}
%\belowtable{} % Table Footnotes
%\end{sidewaystable*}
%
%
%%% MATHEMATICAL EXPRESSIONS
%
%%% All papers typeset by Copernicus Publications follow the math typesetting regulations
%%% given by the IUPAC Green Book (IUPAC: Quantities, Units and Symbols in Physical Chemistry,
%%% 2nd Edn., Blackwell Science, available at: http://old.iupac.org/publications/books/gbook/green_book_2ed.pdf, 1993).
%%%
%%% Physical quantities/variables are typeset in italic font (t for time, T for Temperature)
%%% Indices which are not defined are typeset in italic font (x, y, z, a, b, c)
%%% Items/objects which are defined are typeset in roman font (Car A, Car B)
%%% Descriptions/specifications which are defined by itself are typeset in roman font (abs, rel, ref, tot, net, ice)
%%% Abbreviations from 2 letters are typeset in roman font (RH, LAI)
%%% Vectors are identified in bold italic font using \vec{x}
%%% Matrices are identified in bold roman font
%%% Multiplication signs are typeset using the LaTeX commands \times (for vector products, grids, and exponential notations) or \cdot
%%% The character * should not be applied as mutliplication sign
%
%
%%% EQUATIONS
%
%%% Single-row equation
%
%\begin{equation}
%
%\end{equation}
%
%%% Multiline equation
%
%\begin{align}
%& 3 + 5 = 8\\
%& 3 + 5 = 8\\
%& 3 + 5 = 8
%\end{align}
%
%
%%% MATRICES
%
%\begin{matrix}
%x & y & z\\
%x & y & z\\
%x & y & z\\
%\end{matrix}
%
%
%%% ALGORITHM
%
%\begin{algorithm}
%\caption{...}
%\label{a1}
%\begin{algorithmic}
%...
%\end{algorithmic}
%\end{algorithm}
%
%
%%% CHEMICAL FORMULAS AND REACTIONS
%
%%% For formulas embedded in the text, please use \chem{}
%
%%% The reaction environment creates labels including the letter R, i.e. (R1), (R2), etc.
%
%\begin{reaction}
%%% \rightarrow should be used for normal (one-way) chemical reactions
%%% \rightleftharpoons should be used for equilibria
%%% \leftrightarrow should be used for resonance structures
%\end{reaction}
%
%
%%% PHYSICAL UNITS
%%%
%%% Please use \unit{} and apply the exponential notation (e.g. 20\,\unit{W\,m^{-2}})


\end{document}
